{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11708e0",
   "metadata": {},
   "source": [
    "# X–θ Framework: Clean Analysis\n",
    "\n",
    "This notebook uses a single, DRY, bug-free pipeline for all AB and X–θ analysis.\n",
    "\n",
    "**Only cells after this introduction (Cells 56–64 and dependencies) are authoritative.**\n",
    "\n",
    "Legacy cells using the old `Path` API have been retired for clarity and correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 63: ✍️ Final analysis write-up (saved to paper/analysis/xtheta_analysis_from_tables.md) ---\n",
    "TEXT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "md = TEXT_DIR / \"xtheta_analysis_from_tables.md\"\n",
    "\n",
    "def f(x, nd=3):\n",
    "    try: return f\"{float(x):.{nd}f}\"\n",
    "    except: return str(x)\n",
    "\n",
    "two_pi = 2*np.pi\n",
    "text = f\"\"\"# X–θ Interferometry — Analysis\n",
    "\n",
    "**AB reproduction (θ off).** Phase vs flux is linear with slope **{f(summary_ab['slope'])}** (target 2π = {f(two_pi)}),\n",
    "95% CI [{f(summary_ab['slope_ci95'][0])}, {f(summary_ab['slope_ci95'][1])}],\n",
    "relative error **{f(summary_ab['slope_rel_err_vs_2pi'])}**; intercept {f(summary_ab['intercept'])} rad; R² {f(summary_ab['R2'])}.\n",
    "\n",
    "**θ-only at Φ=0.** Phase vs internal control is linear with slope **{f(summary_theta['slope'],6)}** (target 2π = {f(two_pi,6)}),\n",
    "95% CI [{f(summary_theta['slope_ci95'][0],6)}, {f(summary_theta['slope_ci95'][1],6)}],\n",
    "relative error **{f(summary_theta['slope_rel_err_vs_2pi'],6)}**; intercept {f(summary_theta['intercept'])} rad; R² {f(summary_theta['R2'])}.\n",
    "\n",
    "**Lock-in detectability.** With EM fixed, the FFT peak at the drive frequency shows SNR **{f(master['lockin'].get('snr_on_over_off', np.nan),2)}×**.\n",
    "Sweeping amplitude \\(A_\\theta\\), the peak follows the expected trend \\(|J_1(2\\pi A_\\theta)|\\) with correlation **{f(master['lockin'].get('shape_corr_vs_absJ1', np.nan),3)}**.\n",
    "\n",
    "**Sanity checks.** Stokes’ theorem holds to relative error **{f(master['checks']['stokes_rel_err'],3)}**; topology robustness: max \\(|\\Delta\\varphi-2\\pi f|\\) = **{f(master['checks']['topo_bend_maxabs_rad'],3)}** rad.\n",
    "\n",
    "**Conclusion.** X–θ reproduces the magnetic AB effect and introduces an independent, controllable phase observable even at zero EM flux.\n",
    "The lock-in signature provides a practical detection channel and a falsifiable handle on the internal phase coupling.\n",
    "\"\"\"\n",
    "md.write_text(text, encoding=\"utf-8\")\n",
    "print(\"Wrote:\", md)\n",
    "print(\"\\n--- Preview ---\\n\")\n",
    "print(md.read_text(encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1cb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 56 — constants, repo dirs, exporters, math helpers (single definitions)\n",
    "\n",
    "# constants\n",
    "h    = globals().get(\"h\",    6.62607015e-34)\n",
    "hbar = globals().get(\"hbar\", 1.054571817e-34)\n",
    "e    = globals().get(\"e\",    1.602176634e-19)\n",
    "q    = globals().get(\"q\",   -e)\n",
    "Phi0 = globals().get(\"Phi0\", h/abs(q))\n",
    "\n",
    "# repo dirs → paper/*\n",
    "PROJECT_ROOT_NAME = \"X-theta-framework\"\n",
    "repo_root = Path.cwd().resolve()\n",
    "for p in [repo_root, *repo_root.parents]:\n",
    "    if p.name == PROJECT_ROOT_NAME:\n",
    "        repo_root = p; break\n",
    "PAPER_DIR = repo_root / \"paper\"\n",
    "FIG_DIR   = PAPER_DIR / \"figs\"\n",
    "TAB_DIR   = PAPER_DIR / \"tables\"\n",
    "DATA_DIR  = PAPER_DIR / \"data\"\n",
    "TEXT_DIR  = PAPER_DIR / \"analysis\"\n",
    "for d in [FIG_DIR, TAB_DIR, DATA_DIR, TEXT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR.resolve())\n",
    "print(\"TAB_DIR :\", TAB_DIR.resolve())\n",
    "print(\"TEXT_DIR:\", TEXT_DIR.resolve())\n",
    "\n",
    "# exporters\n",
    "def export_table(df: pd.DataFrame, stem: str, floatfmt=6):\n",
    "    p_csv = DATA_DIR / f\"{stem}.csv\"\n",
    "    p_tex = TAB_DIR  / f\"{stem}.tex\"\n",
    "    df.to_csv(p_csv, index=False)\n",
    "    df.round(floatfmt).to_latex(p_tex, index=False)\n",
    "    print(\"Saved:\", p_csv, \"and\", p_tex)\n",
    "    return p_csv, p_tex\n",
    "\n",
    "def write_json(obj, stem: str):\n",
    "    p = DATA_DIR / f\"{stem}.json\"\n",
    "    p.write_text(json.dumps(obj, indent=2), encoding=\"utf-8\")\n",
    "    print(\"Saved JSON:\", p)\n",
    "    return p\n",
    "\n",
    "# stats helpers\n",
    "def linfit_with_ci(x, y):\n",
    "    x = np.asarray(x, float).ravel()\n",
    "    y = np.asarray(y, float).ravel()\n",
    "    assert x.size == y.size and x.size >= 3\n",
    "    n  = x.size\n",
    "    xm, ym = x.mean(), y.mean()\n",
    "    Sxx = np.sum((x-xm)**2)\n",
    "    Sxy = np.sum((x-xm)*(y-ym))\n",
    "    a = Sxy / (Sxx + 1e-30)\n",
    "    b = ym - a*xm\n",
    "    yhat = a*x + b\n",
    "    resid = y - yhat\n",
    "    RSS = float(np.sum(resid**2))\n",
    "    TSS = float(np.sum((y-ym)**2)) + 1e-30\n",
    "    s2  = RSS / max(n-2, 1)\n",
    "    se_a = float(np.sqrt(s2 / (Sxx + 1e-30)))\n",
    "    se_b = float(np.sqrt(s2 * (1/n + xm*xm/(Sxx + 1e-30))))\n",
    "    z = 1.96\n",
    "    return dict(a=a,b=b,R2=1.0 - RSS/TSS,n=int(n),\n",
    "                ci_a=(a-z*se_a, a+z*se_a), ci_b=(b-z*se_b, b+z*se_b))\n",
    "\n",
    "def J1_series(x, terms=50):\n",
    "    x2 = x/2.0; s = 0.0\n",
    "    for m in range(terms):\n",
    "        s += ((-1)**m) * (x2**(2*m+1)) / (factorial(m)*factorial(m+1))\n",
    "    return s\n",
    "\n",
    "def single_sided_fft_mag(x, Fs):\n",
    "    x = np.asarray(x, float).ravel()\n",
    "    N = int(x.size)\n",
    "    if N < 4:\n",
    "        x = np.pad(x, (0, 4-N))\n",
    "        N = x.size\n",
    "    win = np.hanning(N)\n",
    "    X = np.fft.rfft(x * win)\n",
    "    f = np.fft.rfftfreq(N, d=1.0/float(Fs))\n",
    "    mag = np.abs(X)/N\n",
    "    return f, mag\n",
    "\n",
    "def fft_peak_near(f, mag, f0, bw=1.0):\n",
    "    m = (f >= f0-bw) & (f <= f0+bw)\n",
    "    return 0.0 if not np.any(m) else float(np.max(mag[m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7777bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 57 — geometry & vector potential (single definitions; no pathlib collisions)\n",
    "\n",
    "@dataclass\n",
    "class GeoPath:\n",
    "    x: np.ndarray\n",
    "    y: np.ndarray\n",
    "\n",
    "def make_paths_geo(n=2000, bend=0.4, sep=0.6, xL=-1.2, xR=1.2, y0=0.0):\n",
    "    x = np.linspace(xL, xR, n)\n",
    "    yU = y0 + 0.5*sep*np.tanh(bend*x)\n",
    "    yL = y0 - 0.5*sep*np.tanh(bend*x)\n",
    "    yU[[0,-1]] = y0 + 0.5*sep\n",
    "    yL[[0,-1]] = y0 - 0.5*sep\n",
    "    return GeoPath(x, yU), GeoPath(x, yL)\n",
    "\n",
    "def rectangle_geo(xmin, xmax, ymin, ymax, n_edge=900):\n",
    "    # CCW: bottom→, right↑, top←, left↓\n",
    "    xb = np.linspace(xmin, xmax, n_edge); yb = np.full_like(xb, ymin)\n",
    "    xr = np.full(n_edge, xmax);           yr = np.linspace(ymin, ymax, n_edge)\n",
    "    xt = np.linspace(xmax, xmin, n_edge); yt = np.full_like(xt, ymax)\n",
    "    xl = np.full(n_edge, xmin);           yl = np.linspace(ymax, ymin, n_edge)\n",
    "    x = np.concatenate([xb[:-1], xr[:-1], xt[:-1], xl])\n",
    "    y = np.concatenate([yb[:-1], yr[:-1], yt[:-1], yl])\n",
    "    return GeoPath(x=x, y=y)\n",
    "\n",
    "def make_solenoid_A(Phi, R=0.2):\n",
    "    Phi_fac = Phi/(2*np.pi); R2 = R*R\n",
    "    def Ax(x, y):\n",
    "        r2 = x*x + y*y\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            return -Phi_fac * np.where(r2>R2, y/r2, 0.0)\n",
    "    def Ay(x, y):\n",
    "        r2 = x*x + y*y\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            return  Phi_fac * np.where(r2>R2, x/r2, 0.0)\n",
    "    return Ax, Ay\n",
    "\n",
    "def line_integral_A_geo(Ax, Ay, gp: GeoPath) -> float:\n",
    "    x, y = gp.x, gp.y\n",
    "    xm = 0.5*(x[1:] + x[:-1]); ym = 0.5*(y[1:] + y[:-1])\n",
    "    dx = np.diff(x); dy = np.diff(y)\n",
    "    dl = np.sqrt(dx*dx + dy*dy)\n",
    "    with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "        tx = np.where(dl>0, dx/dl, 0.0); ty = np.where(dl>0, dy/dl, 0.0)\n",
    "    Axd = Ax(xm, ym); Ayd = Ay(xm, ym)\n",
    "    return float(np.sum((Axd*tx + Ayd*ty) * dl))\n",
    "\n",
    "def phase_from_geo(Ax, Ay, P1: GeoPath, P2: GeoPath, charge=q) -> float:\n",
    "    I1 = line_integral_A_geo(Ax, Ay, P1)\n",
    "    I2 = line_integral_A_geo(Ax, Ay, P2)\n",
    "    return (charge/hbar) * (I1 - I2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def export_fig(name_or_path, *, png=True, svg=True, dpi=180, transparent=False):\n",
    "    \"\"\"\n",
    "    Save current figure as PNG/SVG.\n",
    "    If 'name_or_path' has an extension (.png/.svg), use it directly.\n",
    "    If it has no extension, save into FIG_DIR with that stem.\n",
    "    Returns dict {ext: fullpath}.\n",
    "    \"\"\"\n",
    "    p = Path(name_or_path)\n",
    "\n",
    "    # If a full filename (with extension) was passed (old style)\n",
    "    if p.suffix.lower() in {\".png\", \".svg\"}:\n",
    "        base = p.with_suffix(\"\")\n",
    "        base.parent.mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        base = (FIG_DIR / p).with_suffix(\"\")  # new style: just a stem\n",
    "        base.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    out = {}\n",
    "    if png:\n",
    "        png_p = base.with_suffix(\".png\")\n",
    "        plt.savefig(png_p, dpi=dpi, transparent=transparent)\n",
    "        out[\"png\"] = str(png_p.resolve())\n",
    "    if svg:\n",
    "        svg_p = base.with_suffix(\".svg\")\n",
    "        plt.savefig(svg_p, transparent=transparent)\n",
    "        out[\"svg\"] = str(svg_p.resolve())\n",
    "\n",
    "    for k, fp in out.items():\n",
    "        q = Path(fp)\n",
    "        print(f\"Saved {k.upper():>3}: {q}  size={q.stat().st_size if q.exists() else 0}\")\n",
    "    return out\n",
    "\n",
    "# helpers\n",
    "def r2_score(y, yhat):\n",
    "    y = np.asarray(y); yhat = np.asarray(yhat)\n",
    "    ss_res = np.sum((y - yhat)**2)\n",
    "    ss_tot = np.sum((y - np.mean(y))**2) + 1e-30\n",
    "    return 1.0 - ss_res/ss_tot\n",
    "\n",
    "def linfit_with_errors(x, y):\n",
    "    x = np.asarray(x); y = np.asarray(y); n = len(x)\n",
    "    xm, ym = x.mean(), y.mean()\n",
    "    Sxx = np.sum((x-xm)**2); Sxy = np.sum((x-xm)*(y-ym))\n",
    "    a = Sxy / (Sxx + 1e-30); b = ym - a*xm\n",
    "    yhat = a*x + b\n",
    "    resid = y - yhat\n",
    "    RSS = np.sum(resid**2)\n",
    "    s2  = RSS / max(n-2, 1)\n",
    "    se_a = math.sqrt(s2 / (Sxx + 1e-30))\n",
    "    se_b = math.sqrt(s2 * (1/n + xm*xm/(Sxx + 1e-30)))\n",
    "    R2   = 1.0 - RSS / (np.sum((y-ym)**2) + 1e-30)\n",
    "    z = 1.96\n",
    "    return dict(a=a,b=b,R2=R2,n=n, ci_a=(a-z*se_a, a+z*se_a), ci_b=(b-z*se_b, b+z*se_b))\n",
    "\n",
    "def J1_series(x, terms=50):\n",
    "    x2 = x/2.0; s = 0.0\n",
    "    for m in range(terms):\n",
    "        s += ((-1)**m) * (x2**(2*m+1)) / (factorial(m) * factorial(m+1))\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb3176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AB baseline (θ off) — regenerate & save\n",
    "phi_fracs   = np.linspace(-1.0, 1.0, 13)\n",
    "\n",
    "# Minimal DRY geometry/field fallbacks if earlier helpers aren't defined yet\n",
    "if 'make_paths_geo' not in globals():\n",
    "    @dataclass\n",
    "    class GeoPath:\n",
    "        x: np.ndarray\n",
    "        y: np.ndarray\n",
    "    def make_paths_geo(n=2000, bend=0.4, sep=0.6, xL=-1.2, xR=1.2, y0=0.0):\n",
    "        x = np.linspace(xL, xR, n)\n",
    "        yU = y0 + 0.5*sep*np.tanh(bend*x)\n",
    "        yL = y0 - 0.5*sep*np.tanh(bend*x)\n",
    "        yU[[0,-1]] = y0 + 0.5*sep\n",
    "        yL[[0,-1]] = y0 - 0.5*sep\n",
    "        return GeoPath(x, yU), GeoPath(x, yL)\n",
    "    def make_solenoid_A(Phi, R=0.2):\n",
    "        Phi_fac = Phi/(2*np.pi); R2 = R*R\n",
    "        def Ax(x, y):\n",
    "            r2 = x*x + y*y\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                return -Phi_fac * np.where(r2>R2, y/r2, 0.0)\n",
    "        def Ay(x, y):\n",
    "            r2 = x*x + y*y\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                return  Phi_fac * np.where(r2>R2, x/r2, 0.0)\n",
    "        return Ax, Ay\n",
    "    def line_integral_A_geo(Ax, Ay, gp: 'GeoPath') -> float:\n",
    "        x, y = gp.x, gp.y\n",
    "        xm = 0.5*(x[1:] + x[:-1]); ym = 0.5*(y[1:] + y[:-1])\n",
    "        dx = np.diff(x); dy = np.diff(y)\n",
    "        dl = np.sqrt(dx*dx + dy*dy)\n",
    "        with np.errstate(invalid='ignore', divide='ignore'):\n",
    "            tx = np.where(dl>0, dx/dl, 0.0); ty = np.where(dl>0, dy/dl, 0.0)\n",
    "        Axd = Ax(xm, ym); Ayd = Ay(xm, ym)\n",
    "        return float(np.sum((Axd*tx + Ayd*ty) * dl))\n",
    "    def phase_from_geo(Ax, Ay, P1: 'GeoPath', P2: 'GeoPath', charge=None) -> float:\n",
    "        # use q from globals by default\n",
    "        charge = q if charge is None else charge\n",
    "        I1 = line_integral_A_geo(Ax, Ay, P1)\n",
    "        I2 = line_integral_A_geo(Ax, Ay, P2)\n",
    "        return (charge/hbar) * (I1 - I2)\n",
    "\n",
    "# Use existing numeric helper if present; else use DRY path-based computation\n",
    "if 'numerical_em_phase_from_fraction' in globals():\n",
    "    num_phases  = np.array([numerical_em_phase_from_fraction(f) for f in phi_fracs])\n",
    "else:\n",
    "    P1, P2 = make_paths_geo(n=2000, bend=0.4)\n",
    "    num_phases = []\n",
    "    for f in phi_fracs:\n",
    "        Ax, Ay = make_solenoid_A(f*Phi0, R=0.2)\n",
    "        num_phases.append(phase_from_geo(Ax, Ay, P1, P2))\n",
    "    num_phases = np.array(num_phases)\n",
    "\n",
    "theo_phases = 2*np.pi*phi_fracs\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(phi_fracs, num_phases, 'o-', label='Numerical (EM only)')\n",
    "plt.plot(phi_fracs, theo_phases, '--', label='Theory 2π f')\n",
    "plt.xlabel(r'$\\\\Phi/\\\\Phi_0$'); plt.ylabel('phase (rad)')\n",
    "plt.title('AB phase vs flux fraction (θ off)')\n",
    "plt.legend(); plt.grid(True, alpha=0.3)\n",
    "\n",
    "export_fig(Path(FIG_AB_BASELINE).with_suffix(''))  # saves .png and .svg\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1257aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT spectrum with θ ON/OFF — robust defaults + save\n",
    "\n",
    "# Provide robust defaults if earlier cells weren’t run\n",
    "I0  = globals().get('I0', 1.0)\n",
    "V   = globals().get('V', 0.9)\n",
    "phi_em_frac = globals().get('phi_em_frac', 0.35)    # EM flux fraction\n",
    "f_drive     = globals().get('f_drive', 47.0)        # Hz\n",
    "A_theta     = globals().get('A_theta', 0.30)        # θ amplitude (fraction)\n",
    "T           = globals().get('T', 2.0)               # seconds\n",
    "Fs          = globals().get('Fs', 2000)             # samples/sec\n",
    "\n",
    "# Time base\n",
    "t = np.arange(int(T*Fs)) / Fs\n",
    "\n",
    "def intensity_time_series(theta_on=True, noise_sigma=0.01):\n",
    "    phi_em = 2*np.pi*phi_em_frac\n",
    "    if theta_on:\n",
    "        phi_theta_t = 2*np.pi*A_theta*np.sin(2*np.pi*f_drive*t)\n",
    "    else:\n",
    "        phi_theta_t = 0.0*t\n",
    "    It = I0*(1 + V*np.cos(phi_em + phi_theta_t))\n",
    "    if noise_sigma>0:\n",
    "        It = It + np.random.normal(0, noise_sigma, size=It.shape)\n",
    "    return It\n",
    "\n",
    "def single_sided_fft_mag(x, Fs):\n",
    "    X = np.fft.rfft(x * np.hanning(len(x)))\n",
    "    f = np.fft.rfftfreq(len(x), 1/Fs)\n",
    "    mag = np.abs(X)/len(x)\n",
    "    return f, mag\n",
    "\n",
    "def fft_peak_near(f, mag, f0, bw=1.0):\n",
    "    m = (f>=f0-bw) & (f<=f0+bw)\n",
    "    return 0.0 if not np.any(m) else float(np.max(mag[m]))\n",
    "\n",
    "# Simulate\n",
    "It_on  = intensity_time_series(True)\n",
    "It_off = intensity_time_series(False)\n",
    "f_on,  mag_on  = single_sided_fft_mag(It_on,  Fs)\n",
    "f_off, mag_off = single_sided_fft_mag(It_off, Fs)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(f_on,  mag_on,  label='θ driven')\n",
    "plt.plot(f_off, mag_off, label='θ off', alpha=0.8)\n",
    "plt.xlim(0, 200)\n",
    "plt.xlabel('Frequency (Hz)'); plt.ylabel('FFT magnitude (a.u.)')\n",
    "plt.title('Spectral line at drive frequency with θ modulation')\n",
    "plt.legend(); plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout();\n",
    "export_fig(Path(FIG_FFT_THETA_DRIVE).with_suffix(''))\n",
    "plt.show()\n",
    "\n",
    "print(\"FFT peak near f, ON/OFF:\", fft_peak_near(f_on, mag_on, f_drive), fft_peak_near(f_off, mag_off, f_drive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 62 — FIX: Key metrics with auto 95% CIs + robust fallbacks\n",
    "\n",
    "# --- helpers ---\n",
    "def linfit_with_ci(x, y):\n",
    "    \"\"\"\n",
    "    OLS fit with 95% CI for slope/intercept, plus R^2.\n",
    "    Returns dict(a, b, R2, ci_a, ci_b, n).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    y = np.asarray(y, dtype=float).ravel()\n",
    "    assert x.size == y.size and x.size >= 3, \"Need >=3 points for CI\"\n",
    "    n  = x.size\n",
    "    xm, ym = x.mean(), y.mean()\n",
    "    Sxx = np.sum((x - xm)**2)\n",
    "    Sxy = np.sum((x - xm)*(y - ym))\n",
    "    a = Sxy / (Sxx + 1e-30)\n",
    "    b = ym - a*xm\n",
    "    yhat = a*x + b\n",
    "    resid = y - yhat\n",
    "    RSS = float(np.sum(resid**2))\n",
    "    TSS = float(np.sum((y - ym)**2)) + 1e-30\n",
    "    s2  = RSS / max(n - 2, 1)                  # residual variance\n",
    "    se_a = float(np.sqrt(s2 / (Sxx + 1e-30)))\n",
    "    se_b = float(np.sqrt(s2 * (1/n + xm*xm/(Sxx + 1e-30))))\n",
    "    R2   = 1.0 - RSS / TSS\n",
    "    z = 1.96\n",
    "    return {\n",
    "        \"a\": a, \"b\": b, \"R2\": R2, \"n\": int(n),\n",
    "        \"ci_a\": (a - z*se_a, a + z*se_a),\n",
    "        \"ci_b\": (b - z*se_b, b + z*se_b)\n",
    "    }\n",
    "\n",
    "# --- ensure dirs (paper/*) exist ---\n",
    "if \"DATA_DIR\" not in globals() or \"TAB_DIR\" not in globals():\n",
    "    PROJECT_ROOT_NAME = \"X-theta-framework\"\n",
    "    repo_root = Path.cwd().resolve()\n",
    "    for p in [repo_root, *repo_root.parents]:\n",
    "        if p.name == PROJECT_ROOT_NAME:\n",
    "            repo_root = p; break\n",
    "    DATA_DIR = repo_root / \"paper\" / \"data\"\n",
    "    TAB_DIR  = repo_root / \"paper\" / \"tables\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TAB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- AB data (from memory if available, else from CSV) ---\n",
    "try:\n",
    "    x_ab, y_ab = phi_fracs, ph_num\n",
    "except NameError:\n",
    "    df_ab = pd.read_csv(DATA_DIR / \"ab_baseline_table.csv\")\n",
    "    x_ab = df_ab[\"phi_frac_EM\"].to_numpy()\n",
    "    y_ab = df_ab[\"phase_numeric_rad\"].to_numpy()\n",
    "fit_ab = linfit_with_ci(x_ab, y_ab)\n",
    "summary_ab = {\n",
    "    \"slope\": fit_ab[\"a\"],\n",
    "    \"slope_ci95\": fit_ab[\"ci_a\"],\n",
    "    \"intercept\": fit_ab[\"b\"],\n",
    "    \"intercept_ci95\": fit_ab[\"ci_b\"],\n",
    "    \"R2\": fit_ab[\"R2\"],\n",
    "    \"n\": fit_ab[\"n\"],\n",
    "    \"slope_rel_err_vs_2pi\": abs(fit_ab[\"a\"] - 2*np.pi)/abs(2*np.pi)\n",
    "}\n",
    "\n",
    "# --- θ-only data (from memory if available, else from CSV) ---\n",
    "try:\n",
    "    x_th, y_th = theta_fracs, phase_theta\n",
    "except NameError:\n",
    "    df_th = pd.read_csv(DATA_DIR / \"theta_only_table.csv\")\n",
    "    x_th = df_th[\"phi_frac_theta\"].to_numpy()\n",
    "    y_th = df_th[\"phase_total_rad\"].to_numpy()\n",
    "fit_th = linfit_with_ci(x_th, y_th)\n",
    "summary_theta = {\n",
    "    \"slope\": fit_th[\"a\"],\n",
    "    \"slope_ci95\": fit_th[\"ci_a\"],\n",
    "    \"intercept\": fit_th[\"b\"],\n",
    "    \"intercept_ci95\": fit_th[\"ci_b\"],\n",
    "    \"R2\": fit_th[\"R2\"],\n",
    "    \"n\": fit_th[\"n\"],\n",
    "    \"slope_rel_err_vs_2pi\": abs(fit_th[\"a\"] - 2*np.pi)/abs(2*np.pi)\n",
    "}\n",
    "\n",
    "# --- lock-in summary (prefer 'summary_lock'; fallback to 'summary_lockin' or JSON on disk) ---\n",
    "summary_lock = globals().get(\"summary_lock\", None)\n",
    "if summary_lock is None:\n",
    "    summary_lock = globals().get(\"summary_lockin\", None)\n",
    "if summary_lock is None:\n",
    "    try:\n",
    "        summary_lock = json.loads((DATA_DIR / \"lockin_summary.json\").read_text())\n",
    "    except Exception:\n",
    "        summary_lock = {\"snr_on_over_off\": np.nan, \"shape_corr_vs_absJ1\": np.nan}\n",
    "\n",
    "# --- checks table (df_checks in memory or CSV) ---\n",
    "if \"df_checks\" not in globals():\n",
    "    df_checks = pd.read_csv(DATA_DIR / \"checks_stokes_topology_table.csv\")\n",
    "\n",
    "# --- build key metrics table ---\n",
    "key = pd.DataFrame([{\n",
    "    # AB\n",
    "    \"AB slope [rad/unit]\": summary_ab[\"slope\"],\n",
    "    \"AB slope 95% CI low\": summary_ab[\"slope_ci95\"][0],\n",
    "    \"AB slope 95% CI high\": summary_ab[\"slope_ci95\"][1],\n",
    "    \"AB slope rel.err vs 2π\": summary_ab[\"slope_rel_err_vs_2pi\"],\n",
    "    \"AB intercept [rad]\": summary_ab[\"intercept\"],\n",
    "    \"AB intercept 95% CI low\": summary_ab[\"intercept_ci95\"][0],\n",
    "    \"AB intercept 95% CI high\": summary_ab[\"intercept_ci95\"][1],\n",
    "    \"AB R2\": summary_ab[\"R2\"],\n",
    "\n",
    "    # θ-only\n",
    "    \"θ-only slope [rad/unit]\": summary_theta[\"slope\"],\n",
    "    \"θ-only slope 95% CI low\": summary_theta[\"slope_ci95\"][0],\n",
    "    \"θ-only slope 95% CI high\": summary_theta[\"slope_ci95\"][1],\n",
    "    \"θ-only slope rel.err vs 2π\": summary_theta[\"slope_rel_err_vs_2pi\"],\n",
    "    \"θ-only intercept [rad]\": summary_theta[\"intercept\"],\n",
    "    \"θ-only intercept 95% CI low\": summary_theta[\"intercept_ci95\"][0],\n",
    "    \"θ-only intercept 95% CI high\": summary_theta[\"intercept_ci95\"][1],\n",
    "    \"θ-only R2\": summary_theta[\"R2\"],\n",
    "\n",
    "    # lock-in\n",
    "    \"Lock-in shape corr |J1|\": summary_lock.get(\"shape_corr_vs_absJ1\", np.nan),\n",
    "    \"Lock-in SNR (ON/OFF)\": summary_lock.get(\"snr_on_over_off\", np.nan),\n",
    "\n",
    "    # sanity\n",
    "    \"Stokes rel.error\": float(df_checks[\"stokes_rel_err\"].iloc[0]),\n",
    "    \"Topology max |Δφ-2πf| [rad]\": float(df_checks[\"topo_bend_maxabs_rad\"].iloc[0]),\n",
    "}])\n",
    "\n",
    "# --- save outputs ---\n",
    "key_csv = TAB_DIR / \"key_metrics.csv\"\n",
    "key_tex = TAB_DIR / \"key_metrics.tex\"\n",
    "key.to_csv(key_csv, index=False)\n",
    "key.round(6).to_latex(key_tex, index=False)\n",
    "\n",
    "summary_json = DATA_DIR / \"analysis_summary.json\"\n",
    "with open(summary_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"ab\": summary_ab,\n",
    "        \"theta_only\": summary_theta,\n",
    "        \"lockin\": summary_lock,\n",
    "        \"checks\": df_checks.to_dict(orient=\"records\")[0]\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", key_csv, key_tex, summary_json)\n",
    "display(key.round(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da3c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 66 — Discretization convergence (N points along paths)\n",
    "phi_test = 0.43\n",
    "Phi_test = phi_test * Phi0\n",
    "AxT, AyT = make_solenoid_A(Phi_test, R=0.2)\n",
    "\n",
    "# Use smooth shared-endpoint paths that enclose the solenoid (closed loop = P1 + reverse(P2))\n",
    "xL, xR, sep = -1.2, 1.2, 0.7\n",
    "\n",
    "def shared_endpoint_paths(N, sep=sep, xL=xL, xR=xR, y0=0.0):\n",
    "    N = int(N)\n",
    "    x = np.linspace(xL, xR, N)\n",
    "    s = (x - xL) / (xR - xL)\n",
    "    bump = np.sin(np.pi * s) ** 2  # 0 at ends, 1 at center\n",
    "    yU = y0 + 0.5 * sep * bump\n",
    "    yL = y0 - 0.5 * sep * bump\n",
    "    return GeoPath(x, yU), GeoPath(x, yL)\n",
    "\n",
    "Ns = np.array([200, 400, 800, 1600, 3200, 6400])\n",
    "ph_est = []\n",
    "for N in Ns:\n",
    "    P1c, P2c = shared_endpoint_paths(N)\n",
    "    ph_est.append(phase_from_geo(AxT, AyT, P1c, P2c, charge=q))\n",
    "ph_est = np.array(ph_est)\n",
    "ph_true = 2*np.pi*phi_test\n",
    "abs_err = np.abs(ph_est - ph_true)\n",
    "\n",
    "df_conv = pd.DataFrame({\"N_points\": Ns, \"phase_est_rad\": ph_est, \"phase_true_rad\": ph_true, \"abs_err_rad\": abs_err})\n",
    "export_table(df_conv, \"convergence_table\")\n",
    "write_json({\"phi_frac\": float(phi_test), \"errs\": abs_err.tolist(), \"Ns\": Ns.tolist()}, \"convergence_summary\")\n",
    "print(\"Convergence: last two errors:\", abs_err[-2], abs_err[-1])\n",
    "display(df_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba58caa7",
   "metadata": {},
   "source": [
    "### Cell 56: Analysis & Data Tables (Saved to paper/*)\n",
    "\n",
    "This block generates:\n",
    "- CSV + LaTeX tables → `paper/tables/` and/or `paper/data/`\n",
    "- A master metrics JSON → `paper/data/analysis_summary.json`\n",
    "- A short narrative → `paper/analysis/xtheta_analysis_from_tables.md`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f0d3be",
   "metadata": {},
   "source": [
    "## Cell 57 : Generate AB baseline table → paper/tables & paper/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac591b",
   "metadata": {},
   "source": [
    "## Cell 58 : Generate θ-only table at Φ=0 → paper/tables & paper/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47981c38",
   "metadata": {},
   "source": [
    "## Cell 59 : θ-only table (Φ=0) → paper/{data,tables}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a581a",
   "metadata": {},
   "source": [
    "## Cell 59 : Generate lock-in table & SNR → paper/tables & paper/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9eca37",
   "metadata": {},
   "source": [
    "## Cell 60 : Generate Stokes & Topology checks → paper/tables & paper/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24fd69a",
   "metadata": {},
   "source": [
    "## Cell 61: Key metrics table + summary JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183be06",
   "metadata": {},
   "source": [
    "## Cell 62 : Write analysis markdown to paper/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure DATA_DIR and TAB_DIR exist (from earlier cells); reconstruct if missing\n",
    "if \"DATA_DIR\" not in globals() or \"TAB_DIR\" not in globals():\n",
    "    PROJECT_ROOT_NAME = \"X-theta-framework\"\n",
    "    repo_root = Path.cwd().resolve()\n",
    "    for parent in [repo_root, *repo_root.parents]:\n",
    "        if parent.name == PROJECT_ROOT_NAME:\n",
    "            repo_root = parent; break\n",
    "    DATA_DIR = repo_root / \"paper\" / \"data\"\n",
    "    TAB_DIR  = repo_root / \"paper\" / \"tables\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TAB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Stokes (circulation vs enclosed flux) ---\n",
    "Phi_st = 0.5*Phi0\n",
    "Ax_st, Ay_st = make_solenoid_A(Phi_st, R=0.2)\n",
    "\n",
    "rect_out = rectangle_geo(0.4, 1.0, -0.6, 0.6, n_edge=800)   # misses core\n",
    "rect_in  = rectangle_geo(-0.6, 0.6, -0.6, 0.6, n_edge=800)  # encloses core\n",
    "\n",
    "circ_out = line_integral_A_geo(Ax_st, Ay_st, rect_out)\n",
    "circ_in  = line_integral_A_geo(Ax_st, Ay_st, rect_in)\n",
    "rel_err  = abs(circ_in - Phi_st)/abs(Phi_st)\n",
    "\n",
    "# --- Topology (phase independence from path shape) ---\n",
    "phi_frac_const = 0.40\n",
    "Phi_const = phi_frac_const*Phi0\n",
    "Ax_c, Ay_c = make_solenoid_A(Phi_const, R=0.2)\n",
    "\n",
    "bends = np.linspace(0.1, 0.7, 13)\n",
    "phases = []\n",
    "for b in bends:\n",
    "    P1g, P2g = make_paths_geo(bend=b)             # <- GeoPath version (no pathlib collision)\n",
    "    phases.append(phase_from_geo(Ax_c, Ay_c, P1g, P2g, charge=q))\n",
    "\n",
    "phases = np.array(phases)\n",
    "target = 2*np.pi*phi_frac_const\n",
    "abs_dev = phases - target\n",
    "\n",
    "# --- Pack into a single table and save (CSV + LaTeX) ---\n",
    "df_checks = pd.DataFrame({\n",
    "    \"stokes_Phi_Wb\": [Phi_st],\n",
    "    \"circ_out_Wb\": [circ_out],\n",
    "    \"circ_in_Wb\": [circ_in],\n",
    "    \"stokes_rel_err\": [rel_err],\n",
    "    \"topo_bend_std_rad\": [float(np.std(abs_dev))],\n",
    "    \"topo_bend_maxabs_rad\": [float(np.max(np.abs(abs_dev)))]\n",
    "})\n",
    "\n",
    "p_csv = DATA_DIR / \"checks_stokes_topology_table.csv\"\n",
    "p_tex = TAB_DIR  / \"checks_stokes_topology_table.tex\"\n",
    "df_checks.to_csv(p_csv, index=False)\n",
    "df_checks.round(6).to_latex(p_tex, index=False)\n",
    "\n",
    "print(\"Checks saved:\", p_csv.resolve(), \"and\", p_tex.resolve())\n",
    "display(df_checks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e755110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 67 — 2-parameter plane fit Δφ(Φ, Φθ)\n",
    "# Use shared-endpoint, solenoid-enclosing paths as in Cell 66\n",
    "P1p, P2p = (lambda: shared_endpoint_paths(2000))()\n",
    "\n",
    "phi_fracs_grid  = np.linspace(-0.9, 0.9, 19)\n",
    "theta_fracs_grid = np.linspace(-0.9, 0.9, 19)\n",
    "Phi_vals = phi_fracs_grid * Phi0\n",
    "\n",
    "rows = []\n",
    "for f in phi_fracs_grid:\n",
    "    Ax, Ay = make_solenoid_A(f*Phi0, R=0.2)\n",
    "    for th in theta_fracs_grid:\n",
    "        ph_AB = phase_from_geo(Ax, Ay, P1p, P2p, charge=q)\n",
    "        ph_tot = ph_AB + 2*np.pi*th  # linear superposition\n",
    "        rows.append({\"phi_frac_EM\": float(f), \"phi_frac_theta\": float(th), \"phase_total_rad\": float(ph_tot)})\n",
    "\n",
    "df_plane = pd.DataFrame(rows)\n",
    "export_table(df_plane, \"plane_fit_table\")\n",
    "\n",
    "# OLS plane fit: z ≈ a*x + b*y + c\n",
    "X = np.column_stack([df_plane[\"phi_frac_EM\"].values, df_plane[\"phi_frac_theta\"].values, np.ones(len(df_plane))])\n",
    "Y = df_plane[\"phase_total_rad\"].values\n",
    "coef, *_ = np.linalg.lstsq(X, Y, rcond=None)\n",
    "a, b, c = map(float, coef)\n",
    "\n",
    "Yhat = X @ coef\n",
    "SS_res = float(np.sum((Y - Yhat)**2))\n",
    "SS_tot = float(np.sum((Y - np.mean(Y))**2))\n",
    "R2 = 1.0 - SS_res/SS_tot if SS_tot > 0 else 1.0\n",
    "\n",
    "write_json({\"a\": a, \"b\": b, \"c\": c, \"R2\": R2}, \"plane_fit_summary\")\n",
    "print(f\"Plane fit: a={a:.6f}, b={b:.6f}, c={c:.6g}, R^2={R2:.6f}\")\n",
    "display(df_plane.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ebc730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 69 — Reproducibility stamp (env, seeds, params)\n",
    "SEED = 1337\n",
    "np.random.seed(SEED); random.seed(SEED)\n",
    "\n",
    "stamp = {\n",
    "    \"timestamp_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    \"python_version\": sys.version,\n",
    "    \"platform\": platform.platform(),\n",
    "    \"numpy_version\": _np.__version__,\n",
    "    \"params\": {\n",
    "        \"Phi0\": Phi0, \"q\": q, \"hbar\": hbar,\n",
    "        \"lockin\": {\"Fs\": 2000, \"T\": 2.0, \"f_drive\": 47.0, \"phi_em_frac\": 0.35}\n",
    "    },\n",
    "    \"seeds\": {\"python_random\": SEED, \"numpy_random\": SEED}\n",
    "}\n",
    "write_json(stamp, \"run_metadata\")\n",
    "print(\"Saved run metadata:\", (DATA_DIR/\"run_metadata.json\").resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce4737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 70 — Append addendum to markdown write-up\n",
    "addendum_path = PAPER_TEXT_DIR / \"xtheta_analysis_from_tables.md\"\n",
    "with open(addendum_path, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\\n## Addendum: Validation and Reproducibility\\n\\n\")\n",
    "    # Load summaries produced by Cells 65–69\n",
    "    g = json.load(open(PAPER_DATA_DIR/\"gauge_invariance_summary.json\", \"r\"))\n",
    "    c = json.load(open(PAPER_DATA_DIR/\"convergence_summary.json\", \"r\"))\n",
    "    p = json.load(open(PAPER_DATA_DIR/\"plane_fit_summary.json\", \"r\"))\n",
    "    d = json.load(open(PAPER_DATA_DIR/\"lockin_demod_summary.json\", \"r\"))\n",
    "    r = json.load(open(PAPER_DATA_DIR/\"run_metadata.json\", \"r\"))\n",
    "\n",
    "    g_max = g.get(\"max_abs\", g.get(\"max_abs_diff_rad\"))\n",
    "    g_rms = g.get(\"rms_abs\", g.get(\"rms_diff_rad\"))\n",
    "    corr = d.get(\"corr\", d.get(\"corr_demod_vs_absJ1\"))\n",
    "\n",
    "    sec = (\n",
    "        f\"- Gauge invariance (A→A+∇χ): max |Δφ| = {g_max:.3e} rad; RMS = {g_rms:.3e} rad.\\n\"\n",
    "        f\"- Discretization convergence: Ns = {c['Ns']}; last abs errors = {c['errs'][-2]:.3e}, {c['errs'][-1]:.3e} rad.\\n\"\n",
    "        f\"- Plane fit Δφ ≈ a(Φ/Φ0)+b(Φθ/Φθ0)+c: a = {p['a']:.6f}, b = {p['b']:.6f}, c = {p['c']:.3g}, R² = {p['R2']:.6f}.\\n\"\n",
    "        f\"- Lock-in demod vs |J1(2πAθ)|: corr = {corr:.3f}.\\n\"\n",
    "        f\"- Reproducibility: seed = {r.get('seed', 'n/a')}, python = {r.get('python', 'n/a')}, numpy = {r.get('numpy', 'n/a')}.\\n\"\n",
    "    )\n",
    "    f.write(sec)\n",
    "print(f\"Appended addendum to: {addendum_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvmultigpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}