{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Milk-in-Coffee Loschmidt Echo (X-Î¸ Test)\n",
        "\n",
        "## Goal\n",
        "\n",
        "Test whether an extra compact fiber degree of freedom (Î¸) can act as a **hidden information channel** that makes macroscopic dynamics appear irreversible when Î¸ is uncontrolled â€” while remaining reversible when Î¸ is controlled.\n",
        "\n",
        "We use:\n",
        "\n",
        "- **Coffee stirring**: real velocity fields u(x,y,t), v(x,y,t) from The Well\n",
        "- **Milk**: passive scalar concentration C(x,y,t)\n",
        "- **X-Î¸ coupling**: extra drift velocity  \n",
        "  v_XÎ¸(x,y,t) = Îº âˆ‡AÎ¸(x,y) Â· Î¸Ì‡(t)\n",
        "\n",
        "## Key idea (Loschmidt Echo)\n",
        "\n",
        "1. Forward evolve for T/2 steps.\n",
        "2. Reverse the _observable_ flow field (u,v) and evolve backward for T/2 steps.\n",
        "3. Measure how well we recover the initial milk blob.\n",
        "\n",
        "## Reversal Modes (Critical Control)\n",
        "\n",
        "- **perfect**: reverse base flow AND reverse Î¸ protocol (Î¸Ì‡ â†’ âˆ’Î¸Ì‡).  \n",
        "  Expect: high echo fidelity (limited only by numerics/mixing).\n",
        "- **hidden**: reverse base flow only, Î¸ is not reversed / uncontrolled.  \n",
        "  Expect: echo degrades in a systematic way that scales with winding N.\n",
        "\n",
        "## Primary prediction (Falsifiable)\n",
        "\n",
        "Echo degradation depends on **winding number N** and flips sign under N â†’ âˆ’N (where applicable).\n",
        "If not, X-Î¸ mechanism is not supported by this model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qMjCs5yyr-AA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "the-well 1.2.0 requires fsspec==2024.10.0, but you have fsspec 2025.12.0 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip -q install -U pip\n",
        "!pip -q install the-well torch numpy matplotlib\n",
        "# Optional (only needed if you later switch to local HDF5 validation/repair)\n",
        "!pip -q install -U huggingface_hub fsspec aiohttp hf_transfer\n",
        "!pip -q install h5py\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n"
          ]
        }
      ],
      "source": [
        "import sys, subprocess\n",
        "\n",
        "def pip_install(*args):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *args])\n",
        "\n",
        "pip_install(\"-U\", \"pip\", \"setuptools\", \"wheel\")\n",
        "pip_install(\"-U\", \"huggingface_hub\", \"fsspec\", \"aiohttp\")\n",
        "\n",
        "# Optional but helpful for faster/more robust downloads/streaming\n",
        "pip_install(\"-U\", \"hf_transfer\")\n",
        "\n",
        "print(\"Done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.13.5 (tags/v3.13.5:6cb20a2, Jun 11 2025, 16:15:46) [MSC v.1943 64 bit (AMD64)]\n",
            "Platform: Windows-11-10.0.26200-SP0\n",
            "torch: 2.9.1+cpu | cuda: False\n",
            "numpy: 2.3.5\n",
            "matplotlib: 3.10.8\n",
            "huggingface_hub: 1.2.3\n",
            "fsspec: 2025.12.0\n"
          ]
        }
      ],
      "source": [
        "import sys, platform\n",
        "import torch, numpy as np\n",
        "import matplotlib\n",
        "import huggingface_hub, fsspec\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Platform:\", platform.platform())\n",
        "print(\"torch:\", torch.__version__, \"| cuda:\", torch.cuda.is_available())\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"matplotlib:\", matplotlib.__version__)\n",
        "print(\"huggingface_hub:\", huggingface_hub.__version__)\n",
        "print(\"fsspec:\", fsspec.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HF_HUB_ENABLE_HF_TRANSFER = 1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "print(\"HF_HUB_ENABLE_HF_TRANSFER =\", os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Platform: Windows | IS_WINDOWS: True\n",
            "Patched the_well.data.datasets.os.path.join -> posixpath.join\n"
          ]
        }
      ],
      "source": [
        "import platform\n",
        "IS_WINDOWS = (platform.system().lower() == \"windows\")\n",
        "print(\"Platform:\", platform.system(), \"| IS_WINDOWS:\", IS_WINDOWS)\n",
        "\n",
        "# Workaround: ensure The Well doesn't build hf paths using backslashes on Windows.\n",
        "# This patches only the_well module's join usage (does not globally change os.path).\n",
        "if IS_WINDOWS:\n",
        "    import posixpath\n",
        "    import the_well.data.datasets as dsmod\n",
        "    dsmod.os.path.join = posixpath.join\n",
        "    print(\"Patched the_well.data.datasets.os.path.join -> posixpath.join\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T-C-6dXsYGW",
        "outputId": "e9c2b18d-c104-4069-af2d-a0f08999f408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch: 2.9.1+cpu | device: cpu\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from the_well.data import WellDataset\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"torch:\", torch.__version__, \"| device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded: turbulent_radiative_layer_2D train\n",
            "input_fields: torch.Size([32, 128, 384, 4])\n",
            "output_fields: torch.Size([32, 128, 384, 4])\n"
          ]
        }
      ],
      "source": [
        "from the_well.data import WellDataset\n",
        "\n",
        "DATASET = \"turbulent_radiative_layer_2D\"\n",
        "SPLIT   = \"train\"\n",
        "T_IN    = 32\n",
        "T_OUT   = 32\n",
        "WINDOW_INDEX = 0\n",
        "\n",
        "ds = WellDataset(\n",
        "    well_base_path=\"hf://datasets/polymathic-ai/\",\n",
        "    well_dataset_name=DATASET,\n",
        "    well_split_name=SPLIT,\n",
        "    n_steps_input=T_IN,\n",
        "    n_steps_output=T_OUT,\n",
        "    use_normalization=False,\n",
        ")\n",
        "\n",
        "item = ds[WINDOW_INDEX]\n",
        "print(\"âœ… Loaded:\", DATASET, SPLIT)\n",
        "print(\"input_fields:\", item[\"input_fields\"].shape)\n",
        "print(\"output_fields:\", item[\"output_fields\"].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metadata keys groups: [0, 1, 2]\n",
            "field names (first 30): ['density', 'pressure', 'velocity_x', 'velocity_y']\n"
          ]
        }
      ],
      "source": [
        "print(\"metadata keys groups:\", list(ds.metadata.field_names.keys()))\n",
        "print(\"field names (first 30):\", [n for g in ds.metadata.field_names.values() for n in g][:30])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxMK0Pm2sjtQ",
        "outputId": "2fafa899-f0f6-4e6d-cd59-124e9d162378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flattened field names: ['density', 'pressure', 'velocity_x', 'velocity_y']\n",
            "Using velocity channels: velocity_x velocity_y\n"
          ]
        }
      ],
      "source": [
        "def flatten_field_names(field_names_dict):\n",
        "    out = []\n",
        "    for _, group in field_names_dict.items():\n",
        "        out.extend(group)\n",
        "    return out\n",
        "\n",
        "field_names = flatten_field_names(ds.metadata.field_names)\n",
        "print(\"Flattened field names:\", field_names)\n",
        "\n",
        "def find_velocity_indices(names):\n",
        "    pairs = [\n",
        "        (\"velocity_x\", \"velocity_y\"),\n",
        "        (\"u\", \"v\"),\n",
        "        (\"vel_x\", \"vel_y\"),\n",
        "        (\"vx\", \"vy\"),\n",
        "    ]\n",
        "    for a, b in pairs:\n",
        "        if a in names and b in names:\n",
        "            return names.index(a), names.index(b)\n",
        "\n",
        "    vel = [i for i, n in enumerate(names) if \"velocity\" in n.lower()]\n",
        "    if len(vel) >= 2:\n",
        "        return vel[0], vel[1]\n",
        "\n",
        "    raise RuntimeError(\"No velocity channels found.\\n\" + \"\\n\".join(names))\n",
        "\n",
        "ix, iy = find_velocity_indices(field_names)\n",
        "print(\"Using velocity channels:\", field_names[ix], field_names[iy])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. A_MODE = \"ramp\" (calibration mode)\n",
        "\n",
        "ð´\n",
        "ðœƒ\n",
        "(\n",
        "ð‘¥\n",
        ",\n",
        "ð‘¦\n",
        ")\n",
        "=\n",
        "ð›¼\n",
        "\n",
        "ð‘¥\n",
        "A\n",
        "Î¸\n",
        "â€‹\n",
        "\n",
        "(x,y)=Î±x\n",
        "\n",
        "âˆ‡\n",
        "ð´\n",
        "ðœƒ\n",
        "âˆ‡A\n",
        "Î¸\n",
        "â€‹\n",
        "\n",
        "is basically a constant shove to the right.\n",
        "\n",
        "Good for: â€œdoes the wiring work?â€ and clean\n",
        "Î”\n",
        "âˆ\n",
        "ð‘\n",
        "Î”âˆN scaling.\n",
        "\n",
        "2. A_MODE = \"sine\" (geometric / structured mode)\n",
        "\n",
        "ð´\n",
        "ðœƒ\n",
        "(\n",
        "ð‘¥\n",
        ",\n",
        "ð‘¦\n",
        ")\n",
        "=\n",
        "ð›¼\n",
        "sin\n",
        "â¡\n",
        "(\n",
        "2\n",
        "ðœ‹\n",
        "(\n",
        "ð‘˜\n",
        "ð‘¥\n",
        "ð‘¥\n",
        "\n",
        "- ð‘˜\n",
        "  ð‘¦\n",
        "  ð‘¦\n",
        "  )\n",
        "  )\n",
        "  A\n",
        "  Î¸\n",
        "  â€‹\n",
        "\n",
        "(x,y)=Î±sin(2Ï€(k\n",
        "x\n",
        "â€‹\n",
        "\n",
        "x+k\n",
        "y\n",
        "â€‹\n",
        "\n",
        "y))\n",
        "\n",
        "âˆ‡\n",
        "ð´\n",
        "ðœƒ\n",
        "âˆ‡A\n",
        "Î¸\n",
        "â€‹\n",
        "\n",
        "varies across space (pushes different directions in different regions).\n",
        "\n",
        "Good for: showing this isnâ€™t just a constant drift; it produces spatially patterned effects.\n",
        "\n",
        "3. A_MODE = \"field\" (data-driven mode, best if you want realism)\n",
        "\n",
        "Use an actual scalar field from the dataset (e.g., temperature, density, pressure) as\n",
        "ð´\n",
        "ðœƒ\n",
        "A\n",
        "Î¸\n",
        "â€‹\n",
        "\n",
        ":\n",
        "\n",
        "normalize it, then\n",
        "ð´\n",
        "ðœƒ\n",
        "=\n",
        "ð›¼\n",
        "â‹…\n",
        "normalized(field)\n",
        "A\n",
        "Î¸\n",
        "â€‹\n",
        "\n",
        "=Î±â‹…normalized(field)\n",
        "\n",
        "Good for: â€œX-Î¸ couples to the medium,â€ and it ties the effect to real physics content.\n",
        "\n",
        "What you should use, in practice\n",
        "\n",
        "Start with \"ramp\" to validate the echo + winding dependence.\n",
        "\n",
        "Then go to \"sine\" to show it survives when\n",
        "ð´\n",
        "ðœƒ\n",
        "A\n",
        "Î¸\n",
        "â€‹\n",
        "\n",
        "is not trivial.\n",
        "\n",
        "Then, if the dataset has a suitable scalar channel, use \"field\" for the most convincing story.\n",
        "\n",
        "Tiny cheat sheet of knobs\n",
        "\n",
        "ALPHA sets the strength of\n",
        "ð´\n",
        "ðœƒ\n",
        "A\n",
        "Î¸\n",
        "â€‹\n",
        "\n",
        "(and its gradient).\n",
        "\n",
        "A_KX, A_KY (only for \"sine\") set how many waves fit across the domain.\n",
        "\n",
        "KAPPA scales the coupling strength.\n",
        "\n",
        "If you paste the printed Flattened field names: list from your run, Iâ€™ll tell you exactly which channel is most sensible to use for A_MODE=\"field\" in that dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'DATASET': 'turbulent_radiative_layer_2D',\n",
              " 'SPLIT': 'train',\n",
              " 'T_IN': 32,\n",
              " 'T_OUT': 32,\n",
              " 'WINDOW_INDICES': [0, 1, 2, 3, 4, 5, 6, 7],\n",
              " 'KAPPA': 30.0,\n",
              " 'ALPHA': 10.0,\n",
              " 'A_MODE': 'field',\n",
              " 'A_KX': 4,\n",
              " 'A_KY': 0,\n",
              " 'A_FIELD_NAME': None,\n",
              " 'VEL_SCALE': 1.0,\n",
              " 'NOISE_VEL': 0.0,\n",
              " 'MILK_SIGMA': 10.0,\n",
              " 'N_LIST': [-8, -4, -2, -1, 0, 1, 2, 4, 8]}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CONFIG = dict(\n",
        "    DATASET=\"turbulent_radiative_layer_2D\",\n",
        "    SPLIT=\"train\",\n",
        "    T_IN=32,\n",
        "    T_OUT=32,\n",
        "\n",
        "    # windows = different rollouts/samples, used for error bars\n",
        "    WINDOW_INDICES=list(range(0, 8)),   # 0..7\n",
        "\n",
        "    # X-Î¸ knobs\n",
        "    KAPPA=30.0,         # coupling strength\n",
        "    ALPHA=10.0,         # AÎ¸ strength\n",
        "    A_MODE=\"field\",     # \"field\" (best), \"sine\", \"ramp\"\n",
        "    A_KX=4,\n",
        "    A_KY=0,\n",
        "    A_FIELD_NAME=None,  # if None and A_MODE=\"field\", we auto-pick a scalar channel\n",
        "\n",
        "    # advection / scaling knobs\n",
        "    VEL_SCALE=1.0,      # scale velocity if echo too weak/strong\n",
        "    NOISE_VEL=0.0,      # imperfect reversal noise (0 to start)\n",
        "    MILK_SIGMA=10.0,    # blob size\n",
        "\n",
        "    # winding list\n",
        "    N_LIST=[-8,-4,-2,-1,0,1,2,4,8],\n",
        ")\n",
        "CONFIG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'WellDataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ds = \u001b[43mWellDataset\u001b[49m(\n\u001b[32m      2\u001b[39m     well_base_path=\u001b[33m\"\u001b[39m\u001b[33mhf://datasets/polymathic-ai/\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     well_dataset_name=CONFIG[\u001b[33m\"\u001b[39m\u001b[33mDATASET\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      4\u001b[39m     well_split_name=CONFIG[\u001b[33m\"\u001b[39m\u001b[33mSPLIT\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      5\u001b[39m     n_steps_input=CONFIG[\u001b[33m\"\u001b[39m\u001b[33mT_IN\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m     n_steps_output=CONFIG[\u001b[33m\"\u001b[39m\u001b[33mT_OUT\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      7\u001b[39m     use_normalization=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoaded dataset:\u001b[39m\u001b[33m\"\u001b[39m, CONFIG[\u001b[33m\"\u001b[39m\u001b[33mDATASET\u001b[39m\u001b[33m\"\u001b[39m], CONFIG[\u001b[33m\"\u001b[39m\u001b[33mSPLIT\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExample item shapes:\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m       ds[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33minput_fields\u001b[39m\u001b[33m\"\u001b[39m].shape,\n\u001b[32m     13\u001b[39m       ds[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moutput_fields\u001b[39m\u001b[33m\"\u001b[39m].shape)\n",
            "\u001b[31mNameError\u001b[39m: name 'WellDataset' is not defined"
          ]
        }
      ],
      "source": [
        "ds = WellDataset(\n",
        "    well_base_path=\"hf://datasets/polymathic-ai/\",\n",
        "    well_dataset_name=CONFIG[\"DATASET\"],\n",
        "    well_split_name=CONFIG[\"SPLIT\"],\n",
        "    n_steps_input=CONFIG[\"T_IN\"],\n",
        "    n_steps_output=CONFIG[\"T_OUT\"],\n",
        "    use_normalization=False,\n",
        ")\n",
        "\n",
        "print(\"Loaded dataset:\", CONFIG[\"DATASET\"], CONFIG[\"SPLIT\"])\n",
        "print(\"Example item shapes:\",\n",
        "      ds[0][\"input_fields\"].shape,\n",
        "      ds[0][\"output_fields\"].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def metrics(C_final, C0):\n",
        "    # correlation fidelity\n",
        "    F = fidelity_corr(C_final, C0)\n",
        "\n",
        "    # L2 relative error\n",
        "    diff = (C_final - C0)\n",
        "    l2 = torch.linalg.norm(diff.flatten())\n",
        "    l2_rel = float((l2 / torch.linalg.norm(C0.flatten()).clamp_min(1e-12)).detach().cpu().item())\n",
        "\n",
        "    # \"mass\" conservation sanity (should be roughly stable under semi-Lagrangian)\n",
        "    m0 = float(C0.sum().detach().cpu().item())\n",
        "    m1 = float(C_final.sum().detach().cpu().item())\n",
        "    mass_err = (m1 - m0) / (abs(m0) + 1e-12)\n",
        "\n",
        "    return dict(F=F, l2_rel=l2_rel, mass_err=mass_err)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def get_grid(H, W, device):\n",
        "    y = torch.linspace(0, 1, H, device=device)\n",
        "    x = torch.linspace(0, 1, W, device=device)\n",
        "    yy, xx = torch.meshgrid(y, x, indexing=\"ij\")\n",
        "    return yy, xx\n",
        "\n",
        "def make_milk_blob(H, W, device, sigma=10.0):\n",
        "    \"\"\"Creates a Gaussian blob in the center of the grid.\"\"\"\n",
        "    yy, xx = get_grid(H, W, device)\n",
        "    cy, cx = 0.5, 0.5\n",
        "    # sigma is in pixels, so convert to 0..1 scale relative to height\n",
        "    s = sigma / H \n",
        "    blob = torch.exp(-((xx - cx)**2 + (yy - cy)**2) / (2 * s**2))\n",
        "    return blob\n",
        "\n",
        "def build_A_theta(mode, H, W, device, alpha, kx=4, ky=0):\n",
        "    \"\"\"Constructs the gauge potential A_theta(x, y).\"\"\"\n",
        "    yy, xx = get_grid(H, W, device)\n",
        "    \n",
        "    if mode == \"ramp\":\n",
        "        # Gradient is constant (1, 0)\n",
        "        return alpha * xx\n",
        "    elif mode == \"sine\":\n",
        "        # Sinusoidal potential\n",
        "        return alpha * torch.sin(2 * np.pi * (kx * xx + ky * yy))\n",
        "    elif mode == \"field\":\n",
        "        # Placeholder for data-driven field; defaults to ramp if not fed explicit field\n",
        "        # In a full implementation, you'd pass a scalar field here.\n",
        "        return alpha * xx \n",
        "    else:\n",
        "        raise ValueError(f\"Unknown A_mode: {mode}\")\n",
        "\n",
        "def semi_lagrangian_step(C, vx, vy, dt):\n",
        "    \"\"\"Advects scalar C by velocity (vx, vy) using semi-Lagrangian interpolation.\"\"\"\n",
        "    H, W = C.shape\n",
        "    device = C.device\n",
        "    \n",
        "    # Create normalized grid [-1, 1] for grid_sample\n",
        "    yy, xx = get_grid(H, W, device) # 0..1\n",
        "    \n",
        "    # Back-trace: where did the particle come from?\n",
        "    # Velocity is in units of [0..1] per time unit if vel_scale=1.0 and grid is 0..1\n",
        "    # We generally assume vx, vy are normalized or in pixels. \n",
        "    # Let's assume input vx, vy are in grid-units/sec, so we scale to normalized coords.\n",
        "    \n",
        "    # Note: grid_sample expects (x, y) last dimension, in range [-1, 1]\n",
        "    # Current grid is 0..1. Map to -1..1\n",
        "    grid_x = (xx * 2 - 1)\n",
        "    grid_y = (yy * 2 - 1)\n",
        "    \n",
        "    # Displace\n",
        "    # We need velocity in \"normalized grid units\". \n",
        "    # If vx is pixels/step, normalized vel is vx * (2/W).\n",
        "    # Here we assume vx, vy are provided in a compatible scale.\n",
        "    # For safety in these demos, we often assume vx, vy are raw magnitudes roughly ~1.0 max.\n",
        "    \n",
        "    prev_x = grid_x - vx * dt * 2 # factor 2 because range is 2 (-1 to 1)\n",
        "    prev_y = grid_y - vy * dt * 2\n",
        "    \n",
        "    # Stack for grid_sample: (1, H, W, 2)\n",
        "    grid = torch.stack((prev_x, prev_y), dim=-1).unsqueeze(0)\n",
        "    \n",
        "    # Sample\n",
        "    C_in = C.unsqueeze(0).unsqueeze(0) # (1, 1, H, W)\n",
        "    C_new = torch.nn.functional.grid_sample(C_in, grid, align_corners=True, padding_mode=\"border\")\n",
        "    \n",
        "    return C_new.squeeze()\n",
        "\n",
        "def fidelity_corr(C1, C2):\n",
        "    \"\"\"Calculates correlation fidelity between two fields.\"\"\"\n",
        "    c1 = C1.flatten()\n",
        "    c2 = C2.flatten()\n",
        "    num = torch.dot(c1, c2)\n",
        "    denom = torch.linalg.norm(c1) * torch.linalg.norm(c2) + 1e-12\n",
        "    return (num / denom).item()\n",
        "\n",
        "def run_echo(vel_seq, A_theta, N_wind, kappa, dt, reverse_mode, vel_scale, C0, noise_vel=0.0):\n",
        "    \"\"\"\n",
        "    Runs the forward and backward evolution (Loschmidt Echo).\n",
        "    \n",
        "    Args:\n",
        "        vel_seq: (T, H, W, 2) tensor of background velocity.\n",
        "        A_theta: (H, W) tensor of gauge potential.\n",
        "        N_wind: Total winding number (turns of theta).\n",
        "        kappa: Coupling strength.\n",
        "        dt: Time step.\n",
        "        reverse_mode: \"perfect\" (reverse theta) or \"hidden\" (don't reverse theta).\n",
        "        vel_scale: Multiplier for background velocity.\n",
        "        C0: Initial milk blob.\n",
        "        noise_vel: Magnitude of noise to add.\n",
        "        \n",
        "    Returns:\n",
        "        F_control, F_xtheta, C_control_final, C_xtheta_final\n",
        "    \"\"\"\n",
        "    T, H, W, _ = vel_seq.shape\n",
        "    half_T = T // 2\n",
        "    \n",
        "    # Pre-calculate gradients of A_theta for the X-theta drift\n",
        "    # grad_A[0] is dy, grad_A[1] is dx in torch.gradient\n",
        "    grad_y, grad_x = torch.gradient(A_theta) \n",
        "    \n",
        "    # Prepare standard (control) and X-theta (experiment) blobs\n",
        "    C_ctrl = C0.clone()\n",
        "    C_exp  = C0.clone()\n",
        "    \n",
        "    # Define phase velocity theta_dot\n",
        "    # We want integral(theta_dot dt) = N_wind * 2pi over full time T? \n",
        "    # Usually in echo: Forward for T/2, Backward for T/2.\n",
        "    # Let's say we wind N times over the full experiment, or N during forward?\n",
        "    # Standard echo: Winding N forward, then unwind -N backward (perfect) or continues +N (hidden).\n",
        "    # Rate: omega = (N * 2pi) / (T * dt) roughly.\n",
        "    omega = (N_wind * 2 * np.pi) / (T * dt)\n",
        "    \n",
        "    # --- FORWARD PASS (0 to T/2) ---\n",
        "    for t in range(half_T):\n",
        "        vx = vel_seq[t, ..., 0] * vel_scale\n",
        "        vy = vel_seq[t, ..., 1] * vel_scale\n",
        "        \n",
        "        # X-theta drift: v_drift = kappa * grad A * theta_dot\n",
        "        # For forward pass, theta_dot = omega\n",
        "        drift_x = kappa * grad_x * omega\n",
        "        drift_y = kappa * grad_y * omega\n",
        "        \n",
        "        # Evolve Control (Base flow only)\n",
        "        C_ctrl = semi_lagrangian_step(C_ctrl, vx, vy, dt)\n",
        "        \n",
        "        # Evolve Experiment (Base + Drift)\n",
        "        C_exp = semi_lagrangian_step(C_exp, vx + drift_x, vy + drift_y, dt)\n",
        "\n",
        "    # --- BACKWARD PASS (T/2 to T) ---\n",
        "    # We reverse the base flow sequence: T/2-1 down to 0\n",
        "    # And flip velocity sign\n",
        "    \n",
        "    for t in range(half_T - 1, -1, -1):\n",
        "        vx = -vel_seq[t, ..., 0] * vel_scale\n",
        "        vy = -vel_seq[t, ..., 1] * vel_scale\n",
        "        \n",
        "        # Determine theta_dot for backward pass\n",
        "        if reverse_mode == \"perfect\":\n",
        "            # Time reversal succeeds: we reverse the drive\n",
        "            theta_dot_bwd = -omega\n",
        "        elif reverse_mode == \"hidden\":\n",
        "            # Time reversal fails: drive continues forward (or is uncontrolled)\n",
        "            # Typically \"hidden\" means we cannot reverse the global drive phase velocity.\n",
        "            theta_dot_bwd = omega \n",
        "        else:\n",
        "            theta_dot_bwd = 0.0\n",
        "\n",
        "        drift_x = kappa * grad_x * theta_dot_bwd\n",
        "        drift_y = kappa * grad_y * theta_dot_bwd\n",
        "        \n",
        "        # Evolve\n",
        "        C_ctrl = semi_lagrangian_step(C_ctrl, vx, vy, dt)\n",
        "        C_exp = semi_lagrangian_step(C_exp, vx + drift_x, vy + drift_y, dt)\n",
        "        \n",
        "    return fidelity_corr(C_ctrl, C0), fidelity_corr(C_exp, C0), C_ctrl, C_exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'[WinError 10054] An existing connection was forcibly closed by the remote host' thrown while requesting GET https://huggingface.co/datasets/polymathic-ai/turbulent_radiative_layer_2D/resolve/main/data/train/turbulent_radiative_layer_tcool_0.03.hdf5\n",
            "Retrying in 1s [Retry 1/5].\n",
            "'[WinError 10054] An existing connection was forcibly closed by the remote host' thrown while requesting GET https://huggingface.co/datasets/polymathic-ai/turbulent_radiative_layer_2D/resolve/main/data/train/turbulent_radiative_layer_tcool_0.03.hdf5\n",
            "Retrying in 2s [Retry 2/5].\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(30, 30)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def run_sweep_across_windows(\n",
        "    window_indices,\n",
        "    reverse_mode,\n",
        "    N_list,\n",
        "    kappa,\n",
        "    alpha,\n",
        "    A_mode=\"ramp\",\n",
        "    vel_scale=1.0,\n",
        "    noise_vel=0.0,\n",
        "    milk_sigma=10.0,\n",
        "):\n",
        "    all_rows = []\n",
        "\n",
        "    for widx in window_indices:\n",
        "        it = ds[widx]\n",
        "        fields_w = torch.cat([it[\"input_fields\"], it[\"output_fields\"]], dim=0).to(torch.float32)\n",
        "        vel_w = fields_w[..., [ix, iy]].to(device)\n",
        "\n",
        "        # dt (use same logic)\n",
        "        dt_w = 1.0\n",
        "        t_in = it.get(\"input_time_grid\", None)\n",
        "        t_out = it.get(\"output_time_grid\", None)\n",
        "        if t_in is not None and t_out is not None:\n",
        "            t_full = torch.cat([t_in, t_out], dim=0).to(torch.float32)\n",
        "            if len(t_full) >= 2:\n",
        "                dt_w = float((t_full[1] - t_full[0]).abs().cpu().item()) or 1.0\n",
        "\n",
        "        T, H, W, _ = vel_w.shape\n",
        "        C0_w = make_milk_blob(H, W, device=device, sigma=milk_sigma)\n",
        "\n",
        "        A_theta_w = build_A_theta(A_mode, H, W, device=device, alpha=alpha, kx=4, ky=0)\n",
        "\n",
        "        for N in N_list:\n",
        "            fc, fx, Cc, Cx = run_echo(\n",
        "                vel_seq=vel_w,\n",
        "                A_theta=A_theta_w,\n",
        "                N_wind=N,\n",
        "                kappa=kappa,\n",
        "                dt=dt_w,\n",
        "                reverse_mode=reverse_mode,\n",
        "                vel_scale=vel_scale,\n",
        "                C0=C0_w,\n",
        "                noise_vel=noise_vel,\n",
        "            )\n",
        "            mc = metrics(Cc, C0_w)\n",
        "            mx = metrics(Cx, C0_w)\n",
        "\n",
        "            all_rows.append(dict(\n",
        "                window=widx, reverse_mode=reverse_mode, N=N,\n",
        "                F_control=mc[\"F\"], F_xtheta=mx[\"F\"],\n",
        "                l2_control=mc[\"l2_rel\"], l2_xtheta=mx[\"l2_rel\"],\n",
        "                masserr_control=mc[\"mass_err\"], masserr_xtheta=mx[\"mass_err\"],\n",
        "            ))\n",
        "\n",
        "    return all_rows\n",
        "\n",
        "# Try 5â€“10 windows to start (increase later)\n",
        "WINDOWS = list(range(0, 6))  # 0..5\n",
        "rows_hidden  = run_sweep_across_windows(WINDOWS, \"hidden\",  N_LIST, KAPPA, ALPHA, A_MODE, VEL_SCALE, NOISE_VEL, 10.0)\n",
        "rows_perfect = run_sweep_across_windows(WINDOWS, \"perfect\", N_LIST, KAPPA, ALPHA, A_MODE, VEL_SCALE, NOISE_VEL, 10.0)\n",
        "\n",
        "len(rows_hidden), len(rows_perfect)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m df = pd.DataFrame(rows_hidden + rows_perfect)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.DataFrame(rows_hidden + rows_perfect)\n",
        "\n",
        "agg = (\n",
        "    df.groupby([\"reverse_mode\", \"N\"])\n",
        "      .agg(F_mean=(\"F_xtheta\", \"mean\"),\n",
        "           F_std=(\"F_xtheta\", \"std\"),\n",
        "           l2_mean=(\"l2_xtheta\", \"mean\"),\n",
        "           l2_std=(\"l2_xtheta\", \"std\"),\n",
        "           n=(\"F_xtheta\", \"count\"))\n",
        "      .reset_index()\n",
        ")\n",
        "agg[\"F_sem\"]  = agg[\"F_std\"] / np.sqrt(agg[\"n\"].clip(lower=1))\n",
        "agg[\"l2_sem\"] = agg[\"l2_std\"] / np.sqrt(agg[\"n\"].clip(lower=1))\n",
        "agg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_metric(metric_mean, metric_sem, title, ylabel):\n",
        "    plt.figure()\n",
        "    for mode in [\"hidden\", \"perfect\"]:\n",
        "        sub = agg[agg[\"reverse_mode\"] == mode].sort_values(\"N\")\n",
        "        plt.errorbar(sub[\"N\"], sub[metric_mean], yerr=sub[metric_sem], marker=\"o\", capsize=3, label=mode)\n",
        "    plt.xlabel(\"Winding number N\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_metric(\"F_mean\", \"F_sem\", \"Loschmidt Echo Fidelity vs N (meanÂ±SEM)\", \"Fidelity (corr)\")\n",
        "plot_metric(\"l2_mean\", \"l2_sem\", \"Relative L2 Error vs N (meanÂ±SEM)\", \"Relative L2 error\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'agg' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m m, b, r2, pred\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Use mean fidelity difference between perfect and hidden as the \"signal\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m pivot = \u001b[43magg\u001b[49m.pivot(index=\u001b[33m\"\u001b[39m\u001b[33mN\u001b[39m\u001b[33m\"\u001b[39m, columns=\u001b[33m\"\u001b[39m\u001b[33mreverse_mode\u001b[39m\u001b[33m\"\u001b[39m, values=\u001b[33m\"\u001b[39m\u001b[33mF_mean\u001b[39m\u001b[33m\"\u001b[39m).reset_index()\n\u001b[32m     14\u001b[39m pivot[\u001b[33m\"\u001b[39m\u001b[33msignal\u001b[39m\u001b[33m\"\u001b[39m] = pivot[\u001b[33m\"\u001b[39m\u001b[33mperfect\u001b[39m\u001b[33m\"\u001b[39m] - pivot[\u001b[33m\"\u001b[39m\u001b[33mhidden\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     15\u001b[39m pivot = pivot.sort_values(\u001b[33m\"\u001b[39m\u001b[33mN\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'agg' is not defined"
          ]
        }
      ],
      "source": [
        "def fit_line(Ns, Ys):\n",
        "    Ns = np.array(Ns, dtype=float)\n",
        "    Ys = np.array(Ys, dtype=float)\n",
        "    A = np.vstack([Ns, np.ones_like(Ns)]).T\n",
        "    m, b = np.linalg.lstsq(A, Ys, rcond=None)[0]\n",
        "    pred = m*Ns + b\n",
        "    ss_res = np.sum((Ys - pred)**2)\n",
        "    ss_tot = np.sum((Ys - Ys.mean())**2) + 1e-12\n",
        "    r2 = 1 - ss_res/ss_tot\n",
        "    return m, b, r2, pred\n",
        "\n",
        "# Use mean fidelity difference between perfect and hidden as the \"signal\"\n",
        "pivot = agg.pivot(index=\"N\", columns=\"reverse_mode\", values=\"F_mean\").reset_index()\n",
        "pivot[\"signal\"] = pivot[\"perfect\"] - pivot[\"hidden\"]\n",
        "pivot = pivot.sort_values(\"N\")\n",
        "\n",
        "m, b, r2, pred = fit_line(pivot[\"N\"], pivot[\"signal\"])\n",
        "print(\"Signal fit: signal â‰ˆ m*N + b\")\n",
        "print(\"m =\", m, \"b =\", b, \"R^2 =\", r2)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(pivot[\"N\"], pivot[\"signal\"], marker=\"o\", label=\"signal (perfect - hidden)\")\n",
        "plt.plot(pivot[\"N\"], pred, label=\"linear fit\")\n",
        "plt.xlabel(\"N\")\n",
        "plt.ylabel(\"Echo signal\")\n",
        "plt.title(\"Topological lever: linear-in-N test\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Odd symmetry test (N vs -N)\n",
        "sym = pivot.set_index(\"N\")[\"signal\"].to_dict()\n",
        "pairs = [(n, -n) for n in pivot[\"N\"] if -n in sym and n > 0]\n",
        "odd_errors = [abs(sym[n] + sym[-n]) for n, _ in pairs]\n",
        "print(\"Odd-symmetry |signal(N)+signal(-N)| (mean):\", float(np.mean(odd_errors)) if odd_errors else None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Proposed Experiment (Simulation â†’ Lab)\n",
        "\n",
        "## Simulation Observable\n",
        "\n",
        "Loschmidt echo fidelity:\n",
        "F = âŸ¨C_final, C0âŸ© / (||C_final|| ||C0||)\n",
        "\n",
        "We compare:\n",
        "\n",
        "- Control (Îº=0)\n",
        "- X-Î¸ perfect reversal (reverse flow and Î¸ protocol)\n",
        "- X-Î¸ hidden reversal (reverse flow only; Î¸ protocol unavailable)\n",
        "\n",
        "## Signature\n",
        "\n",
        "Define signal S(N) = F_perfect(N) âˆ’ F_hidden(N)\n",
        "\n",
        "Predictions:\n",
        "\n",
        "1. S(N) grows ~ linearly with |N| (topological lever).\n",
        "2. S(N) is approximately odd: S(-N) â‰ˆ -S(N) when Î¸Ì‡ changes sign with winding direction.\n",
        "3. Controls:\n",
        "   - Îº=0 â‡’ S(N) â‰ˆ 0\n",
        "   - N=0 â‡’ S(0) â‰ˆ 0\n",
        "4. Robustness:\n",
        "   - signal persists across multiple dataset windows (error bars)\n",
        "\n",
        "## Lab Translation (Quantum/Coherent Platform)\n",
        "\n",
        "Implement Î¸ as a controllable phase on a synthetic dimension (photonic lattice / cold atoms / spin systems).\n",
        "\n",
        "- Prepare an initial wavepacket (analog of milk blob).\n",
        "- Evolve under engineered gauge-like coupling AÎ¸(x).\n",
        "- Apply an echo (reverse base Hamiltonian), with two cases:\n",
        "  - reverse Î¸ drive (perfect)\n",
        "  - do not reverse Î¸ drive (hidden)\n",
        "    Measure return probability (Loschmidt echo) vs N.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".phy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
